<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Blaze - A Tiny, Hackable Full-Text Search Engine</title>
    <link
      href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css"
      rel="stylesheet"
    />
    <style>
      :root {
        --bg-color: #ffffff;
        --text-color: #333333;
        --border-color: #eeeeee;
        --code-bg: #f8f8f8;
        --accent: #333333;
      }

      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      body {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
          "Helvetica Neue", Arial, sans-serif;
        line-height: 1.6;
        color: var(--text-color);
        background: var(--bg-color);
      }

      .container {
        max-width: 900px;
        margin: 0 auto;
        padding: 2rem;
      }

      header {
        margin-bottom: 3rem;
        padding-bottom: 2rem;
        border-bottom: 2px solid var(--border-color);
      }

      h1 {
        font-size: 3rem;
        font-weight: 700;
        margin-bottom: 1rem;
        letter-spacing: -0.02em;
      }

      .subtitle {
        font-size: 1.25rem;
        color: #666;
        margin-bottom: 1.5rem;
        line-height: 1.5;
      }

      .header-buttons {
        display: flex;
        gap: 1rem;
        flex-wrap: wrap;
      }

      .btn {
        display: inline-block;
        padding: 0.75rem 1.5rem;
        border: 2px solid var(--accent);
        text-decoration: none;
        color: var(--accent);
        font-weight: 600;
        transition: all 0.2s;
        border-radius: 4px;
      }

      .btn:hover {
        background: var(--accent);
        color: white;
      }

      .btn-primary {
        background: var(--accent);
        color: white;
      }

      .btn-primary:hover {
        background: white;
        color: var(--accent);
      }

      h2 {
        font-size: 2rem;
        margin: 3rem 0 1rem;
        padding-bottom: 0.5rem;
        border-bottom: 1px solid var(--border-color);
      }

      h3 {
        font-size: 1.5rem;
        margin: 2rem 0 1rem;
      }

      h4 {
        font-size: 1.25rem;
        margin: 1.5rem 0 0.75rem;
        font-weight: 600;
      }

      p {
        margin-bottom: 1rem;
      }

      .features {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
        gap: 1.5rem;
        margin: 2rem 0;
      }

      .feature-card {
        padding: 1.5rem;
        border: 1px solid var(--border-color);
        border-radius: 4px;
      }

      .feature-card h4 {
        margin-top: 0;
        margin-bottom: 0.5rem;
      }

      pre {
        background: var(--code-bg);
        border: 1px solid var(--border-color);
        border-radius: 4px;
        padding: 1.5rem;
        overflow-x: auto;
        margin: 1rem 0;
        font-size: 0.9rem;
        line-height: 1.5;
      }

      code {
        font-family: "SF Mono", Monaco, "Cascadia Code", "Roboto Mono", Consolas,
          "Courier New", monospace;
        font-size: 0.9em;
        background: var(--code-bg);
        padding: 0.2em 0.4em;
        border-radius: 3px;
      }

      pre code {
        background: none;
        padding: 0;
      }

      .ascii-art {
        font-family: "Courier New", Courier, monospace;
        font-size: 0.85rem;
        line-height: 1.3;
        white-space: pre;
        background: var(--code-bg);
        border: 1px solid var(--border-color);
        border-radius: 4px;
        padding: 1.5rem;
        overflow-x: auto;
        margin: 1rem 0;
      }

      ul {
        margin-left: 2rem;
        margin-bottom: 1rem;
      }

      li {
        margin-bottom: 0.5rem;
      }

      table {
        width: 100%;
        border-collapse: collapse;
        margin: 1rem 0;
      }

      th,
      td {
        padding: 0.75rem;
        text-align: left;
        border-bottom: 1px solid var(--border-color);
      }

      th {
        font-weight: 600;
        background: var(--code-bg);
      }

      .note {
        background: #f0f7ff;
        border-left: 4px solid #0066cc;
        padding: 1rem;
        margin: 1rem 0;
      }

      footer {
        margin-top: 4rem;
        padding-top: 2rem;
        border-top: 1px solid var(--border-color);
        text-align: center;
        color: #666;
      }

      @media (max-width: 768px) {
        .container {
          padding: 1rem;
        }

        h1 {
          font-size: 2rem;
        }

        h2 {
          font-size: 1.5rem;
        }

        .features {
          grid-template-columns: 1fr;
        }
      }
    </style>
  </head>

  <body>
    <div class="container">
      <header>
        <h1>Blaze</h1>
        <p class="subtitle">
          Built for hackers, not hyperscalers. A tiny, hackable full-text search
          engine you can actually fit in your head. Features inverted index with
          skip lists, roaring bitmaps, BM25 ranking, and type-safe query
          builder.
        </p>
        <div class="header-buttons">
          <a href="https://github.com/wizenheimer/blaze" class="btn"
            >View on GitHub</a
          >
          <a
            href="https://pkg.go.dev/github.com/wizenheimer/blaze"
            class="btn btn-primary"
            >Documentation →</a
          >
        </div>
      </header>

      <section>
        <h2>Overview</h2>
        <p>
          Blaze is a Go engine that provides fast, full-text search capabilities
          through an inverted index implementation. It's designed for
          applications that need to search through text documents efficiently
          without relying on external search engines.
        </p>

        <div class="features">
          <div class="feature-card">
            <h4>Inverted Index</h4>
            <p>Maps terms to document positions for instant lookups</p>
          </div>
          <div class="feature-card">
            <h4>Skip Lists</h4>
            <p>Probabilistic data structure providing O(log n) operations</p>
          </div>
          <div class="feature-card">
            <h4>Query Builder</h4>
            <p>
              Type-safe, fluent API for boolean queries with roaring bitmaps
            </p>
          </div>
          <div class="feature-card">
            <h4>BM25 Ranking</h4>
            <p>
              Industry-standard relevance scoring with IDF and length
              normalization
            </p>
          </div>
          <div class="feature-card">
            <h4>Text Analysis</h4>
            <p>
              Tokenization, stemming, stopword filtering, case normalization
            </p>
          </div>
          <div class="feature-card">
            <h4>Hybrid Storage</h4>
            <p>Roaring bitmaps for speed + skip lists for precision</p>
          </div>
        </div>
      </section>

      <section>
        <h2>Installation</h2>
        <pre><code class="language-bash">go get github.com/wizenheimer/blaze</code></pre>
      </section>

      <section>
        <h2>Quick Start</h2>
        <pre><code class="language-go">package main

import (
    "fmt"
    "github.com/wizenheimer/blaze"
)

func main() {
    // Create a new inverted index
    idx := blaze.NewInvertedIndex()

    // Index some documents
    idx.Index(1, "The quick brown fox jumps over the lazy dog")
    idx.Index(2, "A quick brown dog runs fast")
    idx.Index(3, "The lazy cat sleeps all day")

    // Search with BM25 ranking
    matches := idx.RankBM25("quick brown", 10)

    // Print results
    for _, match := range matches {
        fmt.Printf("Document %d (score: %.2f)\n", match.DocID, match.Score)
    }
}</code></pre>
      </section>

      <section>
        <h2>Query Builder API</h2>
        <p>
          The Query Builder provides a type-safe, fluent API for constructing
          complex boolean queries with roaring bitmaps. No string parsing, no
          syntax errors - just clean, composable code.
        </p>

        <h3>Basic Queries</h3>

        <h4>Single Term</h4>
        <pre><code class="language-go">// Find all documents containing "machine"
results := blaze.NewQueryBuilder(idx).
    Term("machine").
    Execute()</code></pre>

        <h4>AND Query</h4>
        <pre><code class="language-go">// Find documents with BOTH "machine" AND "learning"
results := blaze.NewQueryBuilder(idx).
    Term("machine").
    And().
    Term("learning").
    Execute()</code></pre>

        <h4>OR Query</h4>
        <pre><code class="language-go">// Find documents with "python" OR "javascript"
results := blaze.NewQueryBuilder(idx).
    Term("python").
    Or().
    Term("javascript").
    Execute()</code></pre>

        <h4>NOT Query</h4>
        <pre><code class="language-go">// Find documents with "python" but NOT "snake"
results := blaze.NewQueryBuilder(idx).
    Term("python").
    And().Not().
    Term("snake").
    Execute()</code></pre>

        <h4>Complex Grouped Query</h4>
        <pre><code class="language-go">// (machine OR deep) AND learning
results := blaze.NewQueryBuilder(idx).
    Group(func(q *blaze.QueryBuilder) {
        q.Term("machine").Or().Term("deep")
    }).
    And().
    Term("learning").
    Execute()</code></pre>

        <h4>BM25 Ranked Results</h4>
        <pre><code class="language-go">// Get top 10 results ranked by relevance
matches := blaze.NewQueryBuilder(idx).
    Term("machine").
    And().
    Term("learning").
    ExecuteWithBM25(10)

for _, match := range matches {
    fmt.Printf("Doc %d: score=%.2f\n", match.DocID, match.Score)
}</code></pre>

        <h3>Convenience Functions</h3>
        <pre><code class="language-go">// AllOf: Documents containing ALL terms (AND operation)
results := blaze.AllOf(idx, "machine", "learning", "python")

// AnyOf: Documents containing ANY term (OR operation)
results := blaze.AnyOf(idx, "cat", "dog", "bird")

// TermExcluding: Term with exclusion (AND NOT operation)
results := blaze.TermExcluding(idx, "python", "snake")</code></pre>
      </section>

      <section>
        <h2>Architecture</h2>

        <h3>Query Processor Architecture</h3>
        <p>
          The query processor uses a hybrid storage approach combining roaring
          bitmaps for document-level operations and skip lists for
          position-level operations.
        </p>

        <div class="ascii-art">
          ┌─────────────────────────────────────────────────────────────────────────┐
          │ QUERY PROCESSOR ARCHITECTURE │
          └─────────────────────────────────────────────────────────────────────────┘
          User Query "machine AND learning" │ ▼ ┌─────────────────────────────┐
          │ Text Analyzer │ │ (tokenize, stem, etc.) │
          └──────────────┬──────────────┘ │ ["machine", "learning"] │ ▼
          ┌─────────────────────────────┐ │ Query Builder │ │ (constructs query
          tree) │ └──────────────┬──────────────┘ │ Query Tree: AND(machine,
          learning) │ ┌─────────────────────┼─────────────────────┐ │ │ │ ▼ ▼ ▼
          ┌───────────────┐ ┌───────────────┐ ┌───────────────┐ │ Bitmap Ops │ │
          Skip List │ │ BM25 Scorer │ │ (fast AND/OR)│ │ (positions) │ │
          (ranking) │ └───────┬───────┘ └───────┬───────┘ └───────┬───────┘ │ │
          │ └─────────────────────┼─────────────────────┘ │ ▼ ┌───────────────┐
          │ Results │ │ (ranked docs)│ └───────────────┘
        </div>

        <h3>Hybrid Storage Model</h3>
        <p>
          Blaze uses a sophisticated hybrid storage model that combines the
          speed of roaring bitmaps with the precision of skip lists.
        </p>

        <div class="ascii-art">
          ┌─────────────────────────────────────────────────────────────────────────┐
          │ HYBRID STORAGE MODEL │
          └─────────────────────────────────────────────────────────────────────────┘
          For each term "machine":
          ┌─────────────────────────────────────────────────────────────────────────┐
          │ DOCUMENT LEVEL (Roaring Bitmap) │ │
          ──────────────────────────────────────────────────────────────────────
          │ │ │ │ DocBitmaps["machine"] = {1, 2, 4, 5, 100, 500, 1000, ...} │ │
          │ │ Compressed representation of ALL documents containing "machine" │
          │ Use: Fast boolean operations (AND, OR, NOT) │ │ Size: ~60 KB for
          500k documents (400x compression!) │ │ │
          └─────────────────────────────────────────────────────────────────────────┘
          │ │ Links to ▼
          ┌─────────────────────────────────────────────────────────────────────────┐
          │ POSITION LEVEL (Skip List) │ │
          ──────────────────────────────────────────────────────────────────────
          │ │ │ │ PostingsList["machine"] = SkipList: │ │ │ │ Level 2:
          [Doc1:Pos5] ────────────────────────> [Doc100:Pos12] │ │ │ │ │ │ Level
          1: [Doc1:Pos5] ──> [Doc2:Pos3] ───────────> [Doc100:Pos12] │ │ │ │ │ │
          │ Level 0: [Doc1:Pos5] -> [Doc2:Pos3] -> [Doc4:Pos1] -> [Doc5:Pos7] │
          │ -> [Doc100:Pos12] -> [Doc500:Pos2] -> ... │ │ │ │ Detailed position
          information for EVERY occurrence │ │ Use: Phrase search, proximity
          ranking, snippets │ │ Size: ~24 MB for 500k positions │ │ │
          └─────────────────────────────────────────────────────────────────────────┘
          WHY HYBRID? ─────────── 1. Bitmaps: Lightning-fast document filtering
          (AND, OR, NOT in microseconds) 2. Skip Lists: Precise position
          tracking for phrases and proximity 3. Best of both worlds: Speed +
          Precision
        </div>

        <h3>Query Execution Flow</h3>
        <p>
          Here's how a complex query executes step-by-step, showcasing the power
          of the hybrid storage approach.
        </p>

        <div class="ascii-art">
          QUERY: (machine OR deep) AND learning AND NOT neural
          ┌─────────────────────────────────────────────────────────────────────────┐
          │ STEP 1: BITMAP PHASE (Fast Document Filtering) │
          └─────────────────────────────────────────────────────────────────────────┘
          Term Lookups (O(1) hash map): DocBitmaps["machine"] = {1, 2, 4, 5, 7,
          8, 9, 10} DocBitmaps["deep"] = {2, 3, 5, 6, 8, 9}
          DocBitmaps["learning"]= {1, 2, 4, 5, 6, 7, 8, 9, 10}
          DocBitmaps["neural"] = {3, 6, 8, 9} Boolean Operations (O(1) per
          chunk): Step 1: machine OR deep {1, 2, 4, 5, 7, 8, 9, 10} ∪ {2, 3, 5,
          6, 8, 9} = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10} Step 2: (machine OR deep)
          AND learning {1, 2, 3, 4, 5, 6, 7, 8, 9, 10} ∩ {1, 2, 4, 5, 6, 7, 8,
          9, 10} = {1, 2, 4, 5, 6, 7, 8, 9, 10} Step 3: Result AND NOT neural
          {1, 2, 4, 5, 6, 7, 8, 9, 10} \ {3, 6, 8, 9} = {1, 2, 4, 5, 7, 10} ←
          CANDIDATE DOCUMENTS Time: ~10 microseconds for 1M documents!
          ┌─────────────────────────────────────────────────────────────────────────┐
          │ STEP 2: POSITION PHASE (Optional - for phrases/proximity) │
          └─────────────────────────────────────────────────────────────────────────┘
          IF phrase search needed: For each candidate doc {1, 2, 4, 5, 7, 10}:
          Use skip lists to verify exact positions Check consecutive positions
          for phrases Extract position data for snippets Time: O(log n) per
          position lookup
          ┌─────────────────────────────────────────────────────────────────────────┐
          │ STEP 3: RANKING PHASE (BM25 Scoring) │
          └─────────────────────────────────────────────────────────────────────────┘
          For each candidate document: 1. Calculate IDF (Inverse Document
          Frequency): - Uses bitmap cardinality for instant document counts -
          IDF("machine") = log((N - df + 0.5) / (df + 0.5)) - df =
          DocBitmaps["machine"].GetCardinality() 2. Calculate TF (Term
          Frequency): - Retrieves from pre-computed DocStats - TF("machine",
          Doc1) = termFreqs["machine"] 3. Apply BM25 formula: - Combines IDF,
          TF, and length normalization - Score = IDF × (TF × (k1 + 1)) / (TF +
          k1 × length_norm) 4. Sum scores for all query terms Results sorted by
          score: Doc 5: 8.45 Doc 2: 7.23 Doc 1: 6.91 ... Time: O(candidates ×
          terms)
        </div>

        <h3>Roaring Bitmap Internals</h3>
        <p>
          Roaring bitmaps provide exceptional compression and performance
          through adaptive container selection.
        </p>

        <div class="ascii-art">
          ┌─────────────────────────────────────────────────────────────────────────┐
          │ ROARING BITMAP STRUCTURE │
          └─────────────────────────────────────────────────────────────────────────┘
          Document IDs: {1, 2, 3, 100, 101, 102, 500000, 500001, 999999}
          Traditional Bitmap (naive): [1,1,1,0,0...0,1,1,1,0...0,1,1,0...0,1]
          Size: 1,000,000 bits = 125 KB (wasteful for sparse data) Roaring
          Bitmap (smart): Split into 65,536 chunks (high 16 bits = chunk ID):
          Chunk 0 (docs 0-65535): [1,2,3,100,101,102] Chunk 7 (docs
          458752-524287): [500000, 500001] Chunk 15 (docs 983040-1048575):
          [999999] Storage per chunk (adaptive):
          ┌────────────────────────────────────────────────────┐ │ If
          cardinality < 4096: │ │ → Use Array Container │ │ → Store sorted
          uint16 values directly │ │ → Size: 2 bytes × cardinality │ │ │ │ If
          cardinality > 4096: │ │ → Use Bitmap Container │ │ → Store 65536-bit
          bitmap (8 KB) │ │ → Size: 8 KB fixed │ │ │ │ If cardinality = 65536
          (all docs): │ │ → Use Run Container │ │ → Store: [0-65535] │ │ → Size:
          4 bytes │ └────────────────────────────────────────────────────┘ Total
          Size: ~60 bytes (vs 125 KB!) Operations: AND: Container-by-container
          intersection Skip non-matching chunks (O(1)) Intersect matching chunks
          (O(min(n,m))) OR: Container-by-container union Merge all chunks
          (O(n+m)) NOT: Complement within document space Flip all bits in each
          chunk
        </div>

        <h3>Memory Layout</h3>
        <p>
          Understanding the memory layout helps optimize for large-scale
          deployments.
        </p>

        <div class="ascii-art">
          ┌─────────────────────────────────────────────────────────────────────────┐
          │ INVERTED INDEX STRUCTURE │
          └─────────────────────────────────────────────────────────────────────────┘
          InvertedIndex {
          ┌─────────────────────────────────────────────────────────────────┐ │
          DocBitmaps: map[string]*roaring.Bitmap │ │
          ───────────────────────────────────────────────────────────────│ │
          "machine" → [Compressed Bitmap: 512 bytes] │ │ "learning" →
          [Compressed Bitmap: 448 bytes] │ │ "deep" → [Compressed Bitmap: 256
          bytes] │ │ ... │ │ │ │ Memory: ~100 bytes per term (compressed) │
          └─────────────────────────────────────────────────────────────────┘ │
          │ Parallel Storage ▼
          ┌─────────────────────────────────────────────────────────────────┐ │
          PostingsList: map[string]SkipList │ │
          ───────────────────────────────────────────────────────────────│ │
          "machine" → SkipList with 10,000 position nodes │ │ "learning" →
          SkipList with 8,000 position nodes │ │ "deep" → SkipList with 5,000
          position nodes │ │ ... │ │ │ │ Memory: ~48 bytes per position (node
          overhead) │
          └─────────────────────────────────────────────────────────────────┘ │
          │ Statistics ▼
          ┌─────────────────────────────────────────────────────────────────┐ │
          DocStats: map[int]DocumentStats │ │
          ───────────────────────────────────────────────────────────────│ │
          Doc1 → {Length: 150, TermFreqs: {"machine": 3, ...}} │ │ Doc2 →
          {Length: 200, TermFreqs: {"learning": 5, ...}} │ │ ... │ │ │ │ Memory:
          ~16 bytes per term per document │
          └─────────────────────────────────────────────────────────────────┘
          Mutex for thread safety (sync.RWMutex) } MEMORY BREAKDOWN (for 1M
          documents, 10M unique positions):
          ────────────────────────────────────────────────────────────
          DocBitmaps: ~10 MB (compressed bitmaps) PostingsList: ~480 MB (skip
          list nodes) DocStats: ~500 MB (per-doc statistics) Overhead: ~10 MB
          (maps, pointers, etc.)
          ──────────────────────────────────────────────────────────── TOTAL: ~1
          GB
        </div>
      </section>

      <section>
        <h2>Performance</h2>

        <h3>Benchmarks</h3>
        <table>
          <thead>
            <tr>
              <th>Operation</th>
              <th>Ops/sec</th>
              <th>Time/op</th>
              <th>Allocs/op</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Query Builder (Simple)</td>
              <td>440,616</td>
              <td>2,511 ns</td>
              <td>39</td>
            </tr>
            <tr>
              <td>Query Builder (Complex)</td>
              <td>222,024</td>
              <td>5,333 ns</td>
              <td>98</td>
            </tr>
            <tr>
              <td>Query Builder (BM25)</td>
              <td>411,124</td>
              <td>2,955 ns</td>
              <td>46</td>
            </tr>
            <tr>
              <td>Term Search</td>
              <td>300,000</td>
              <td>4,123 ns</td>
              <td>3</td>
            </tr>
            <tr>
              <td>Phrase Search</td>
              <td>100,000</td>
              <td>12,456 ns</td>
              <td>12</td>
            </tr>
          </tbody>
        </table>

        <h3>Operation Costs</h3>
        <table>
          <thead>
            <tr>
              <th>Operation</th>
              <th>Complexity</th>
              <th>Why It's Fast</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Bitmap AND</td>
              <td>O(1) per chunk</td>
              <td>Roaring bitmap intersection</td>
            </tr>
            <tr>
              <td>Bitmap OR</td>
              <td>O(1) per chunk</td>
              <td>Roaring bitmap union</td>
            </tr>
            <tr>
              <td>Bitmap NOT</td>
              <td>O(1) per chunk</td>
              <td>Roaring bitmap difference</td>
            </tr>
            <tr>
              <td>Term Lookup</td>
              <td>O(1)</td>
              <td>Direct hash map access</td>
            </tr>
            <tr>
              <td>Position Lookup</td>
              <td>O(log n)</td>
              <td>Skip list binary search</td>
            </tr>
          </tbody>
        </table>
      </section>

      <section>
        <h2>Search Operations</h2>

        <h3>Phrase Search</h3>
        <p>
          Find exact sequences of words. Blaze uses skip lists to efficiently
          verify consecutive positions.
        </p>

        <div class="ascii-art">
          SEARCHING FOR PHRASE: "brown fox" Document: "the quick brown dog
          jumped over the brown fox" Positions: 0 1 2 3 4 5 6 7 8 Phase 1: Find
          END (last word "fox")
          ┌─────────────────────────────────────────────────────────┐ │ Find
          "brown" → Doc:Pos2 │ │ Find "fox" after Pos2 → Doc:Pos8 ← END position
          │ └─────────────────────────────────────────────────────────┘ Phase 2:
          Walk BACKWARDS from END to find START
          ┌─────────────────────────────────────────────────────────┐ │ From
          Pos9, find previous "brown" → Doc:Pos7 ← START │
          └─────────────────────────────────────────────────────────┘ Phase 3:
          Validate ┌─────────────────────────────────────────────────────────┐ │
          Start: Pos7, End: Pos8 │ │ Distance: 8 - 7 = 1 │ │ Expected: 2 words -
          1 = 1 MATCH! │ │ │ │ "brown" "fox" │ │ ▲ ▲ │ │ Pos7 Pos8 (consecutive
          positions) │
          └─────────────────────────────────────────────────────────┘
        </div>

        <pre><code class="language-go">// Find exact phrase "quick brown fox"
matches := idx.FindAllPhrases("quick brown fox", blaze.BOFDocument)

for _, match := range matches {
    start, end := match[0], match[1]
    fmt.Printf("Found in Doc %d from Pos %d to %d\n",
        int(start.DocumentID), int(start.Offset), int(end.Offset))
}</code></pre>

        <h3>Proximity Search</h3>
        <p>
          Find documents containing all terms (not necessarily consecutive).
          Score documents by how close the terms appear together.
        </p>

        <div class="ascii-art">
          SEARCHING FOR: ["quick", "fox"] (any order, not necessarily
          consecutive) Document: "the quick brown dog jumped over the lazy fox"
          Positions: 0 1 2 3 4 5 6 7 8 Phase 1: Find COVER END (furthest term)
          ┌──────────────────────────────────────────────────────────────┐ │
          Find "quick" after BOF → Doc:Pos1 │ │ Find "fox" after BOF → Doc:Pos8
          ← FURTHEST (cover end) │
          └──────────────────────────────────────────────────────────────┘ Phase
          2: Find COVER START (earliest term before end)
          ┌──────────────────────────────────────────────────────────────┐ │
          Find "quick" before Pos9 → Doc:Pos1 ← EARLIEST (cover start)│ │ Find
          "fox" before Pos9 → Doc:Pos8 │
          └──────────────────────────────────────────────────────────────┘ Phase
          3: Calculate Proximity Score
          ┌──────────────────────────────────────────────────────────────┐ │
          Cover: [Pos1, Pos8] │ │ Same document? Yes │ │ All terms present? Yes
          │ │ │ │ "quick" ... ... ... ... ... ... ... "fox" │ │ ▲ ▲ │ │ Pos1
          Pos8 │ │ └────────── Cover Range ──────────────┘ │ │ │ │ Proximity
          Score: 1 / (8 - 1 + 1) = 1/8 = 0.125 │
          └──────────────────────────────────────────────────────────────┘
          PROXIMITY SCORING EXAMPLES: ─────────────────────────── Doc 1:
          "machine learning is machine learning" Pos:0 1 2 3 4 Cover 1: [Pos
          0-1] → score += 1/(1-0+1) = 1/2 = 0.500 Cover 2: [Pos 3-4] → score +=
          1/(4-3+1) = 1/2 = 0.500 ───────────────────────────── Total Score:
          1.000 Doc 2: "learning about machine and learning" Pos:0 1 2 3 4 Cover
          1: [Pos 0-2] → score += 1/(2-0+1) = 1/3 = 0.333 Cover 2: [Pos 2-4] →
          score += 1/(4-2+1) = 1/3 = 0.333 ───────────────────────────── Total
          Score: 0.666 Doc 3: "machine ... ... ... ... learning" Pos:0 1 2 3 4 5
          Cover 1: [Pos 0-5] → score += 1/(5-0+1) = 1/6 = 0.167
          ───────────────────────────── Total Score: 0.167 Ranking: Doc 1
          (1.000) > Doc 2 (0.666) > Doc 3 (0.167) ▲ ▲ ▲ Terms closest Terms
          medium Terms far apart
        </div>

        <pre><code class="language-go">// Rank documents by proximity
matches := idx.RankProximity("quick brown", 5)

for _, match := range matches {
    fmt.Printf("Doc %d: Score %.2f\n",
        int(match.Offsets[0].DocumentID),
        match.Score)
}</code></pre>

        <h3>Skip Lists Explained</h3>
        <p>
          Skip lists are the core data structure for position tracking. They
          provide O(log n) operations while being simpler than balanced trees.
        </p>

        <div class="ascii-art">
          SKIP LIST STRUCTURE: Multiple levels like express lanes Level 3: HEAD
          ────────────────────────────────> [30] ───────> NULL ↓ ↓ Level 2: HEAD
          ─────────────> [15] ────────────> [30] ───────> NULL ↓ ↓ ↓ Level 1:
          HEAD ─────> [10] ──> [15] ──> [20] ──> [30] ───────> NULL ↓ ↓ ↓ ↓ ↓
          Level 0: HEAD ─> [5] ─> [10] ─> [15] ─> [20] ─> [25] ─> [30] ─> [35]
          ─> NULL (ALL NODES AT LEVEL 0) ┌───────┐ │ Node │ Each node has a
          "tower" of forward pointers ├───────┤ │ Key │ Example: Node [15]
          ├───────┤ │ Lvl 3 │ ──> [30] (skip far ahead) │ Lvl 2 │ ──> [30] (skip
          ahead) │ Lvl 1 │ ──> [20] (skip a little) │ Lvl 0 │ ──> [20] (next
          node) └───────┘ SEARCHING FOR KEY = 20: ───────────────────────
          Step-by-Step Search: Level 3: [HEAD] ───────────────────────────────>
          [30] (30 > 20, drop down) ↓ Level 2: [HEAD] ──────────────> [15]
          ─────────> [30] (15 < 20, advance) ↓ Level 2: [15] ─────────> [30] (30
          > 20, drop down) ↓ Level 1: [15] ──> [20] (20 = 20, FOUND!) ^^^^
          Journey Recorded (used for insertions/deletions):
          ┌───────────┬─────────────────┐ │ Level 3 │ HEAD │ │ Level 2 │ [15] │
          │ Level 1 │ [15] │ │ Level 0 │ [15] │ └───────────┴─────────────────┘
          Time Complexity: O(log n) on average HEIGHT DISTRIBUTION
          (Probabilistic): ──────────────────────────────────── For 1000 nodes:
          Level 0: ~1000 nodes (all) ████████████████████████████████████████
          Level 1: ~500 nodes ████████████████████ Level 2: ~250 nodes
          ██████████ Level 3: ~125 nodes █████ Level 4: ~62 nodes ██
        </div>

        <h3>Text Analysis Pipeline</h3>
        <p>
          Blaze transforms raw text into searchable tokens through a multi-stage
          pipeline.
        </p>

        <div class="ascii-art">
          ┌─────────────────────────────────────────────────────────────────────┐
          │ Text Analysis Pipeline │
          └─────────────────────────────────────────────────────────────────────┘
          │ ▼ ┌────────────────────────────────────────┐ │ 1. Tokenization │ │
          Split on non-alphanumeric chars │
          └────────────────┬───────────────────────┘ ▼
          ┌────────────────────────────────────────┐ │ 2. Lowercasing │ │
          Normalize case ("Quick" → "quick") │
          └────────────────┬───────────────────────┘ ▼
          ┌────────────────────────────────────────┐ │ 3. Stopword Filtering │ │
          Remove common words (the, a, is) │
          └────────────────┬───────────────────────┘ ▼
          ┌────────────────────────────────────────┐ │ 4. Length Filtering │ │
          Remove tokens < 2 chars │ └────────────────┬───────────────────────┘ ▼
          ┌────────────────────────────────────────┐ │ 5. Stemming
          (Snowball/Porter2) │ │ Reduce to root ("running" → "run") │
          └────────────────┬───────────────────────┘ ▼ Final Tokens EXAMPLE
          TRANSFORMATION: ─────────────────────── Input: "The Quick Brown Fox
          Jumps!" │ ├─ Step 1: Tokenization │ └─> ["The", "Quick", "Brown",
          "Fox", "Jumps"] │ ├─ Step 2: Lowercasing │ └─> ["the", "quick",
          "brown", "fox", "jumps"] │ ├─ Step 3: Stopword Filtering (remove
          "the") │ └─> ["quick", "brown", "fox", "jumps"] │ ├─ Step 4: Length
          Filtering (all pass >= 2 chars) │ └─> ["quick", "brown", "fox",
          "jumps"] │ └─ Step 5: Stemming ("jumps" → "jump") └─> ["quick",
          "brown", "fox", "jump"]
        </div>

        <h3>BM25 Algorithm</h3>
        <p>
          BM25 (Best Matching 25) is the industry-standard ranking function used
          by Elasticsearch, Solr, and Lucene. It considers term frequency,
          document length, and term rarity.
        </p>

        <div class="ascii-art">
          BM25 FORMULA: ───────────── IDF(q_i) × TF(q_i, D) × (k1 + 1) BM25(D,
          Q) = SUM ───────────────────────────────────────── q_i TF(q_i, D) + k1
          × (1 - b + b × |D|/avgdl) in Q Where: D = Document being scored Q =
          Query (set of terms q_1, q_2, ..., q_n) q_i = Individual query term
          IDF = Inverse Document Frequency (term rarity) TF = Term Frequency
          (occurrences in document) k1 = 1.5 (term frequency saturation
          parameter) b = 0.75 (length normalization parameter) |D| = Document
          length avgdl = Average document length WHAT BM25 CONSIDERS:
          ──────────────────── 1. Term Frequency: How often does the term
          appear? More occurrences = higher relevance 2. TF Saturation:
          Diminishing returns 3→10 occurrences matters less than 0→3 3. Document
          Length: Normalize by document size Prevents long docs from dominating
          results 4. Term Rarity: Rare terms are more important "quantum" >
          "the" in importance TERM FREQUENCY SATURATION:
          ────────────────────────── Score Contribution (with k1=1.5, b=0.75) ^
          | /--------------- (saturation) | / 3 | / | / 2 | / | / 1 | / | / 0
          |______/ +---+---+---+---+---+---+---+---+---+---+---> Term Frequency
          0 1 2 3 4 5 6 7 8 9 10 Key: Going from 0→3 occurrences adds more to
          the score than going from 7→10 occurrences (diminishing returns)
        </div>

        <pre><code class="language-go">// Search and rank using BM25
results := idx.RankBM25("machine learning", 10)

for _, match := range results {
    fmt.Printf("Doc %d: Score %.2f\n",
        match.DocID,
        match.Score)
}</code></pre>
      </section>

      <section>
        <h2>Real-World Examples</h2>

        <h3>E-commerce Search</h3>
        <pre><code class="language-go">func SearchProducts(idx *blaze.InvertedIndex, query string, 
                    category string, excludeOutOfStock bool) []blaze.Match {
    qb := blaze.NewQueryBuilder(idx).Term(query)
    
    // Add category filter
    if category != "" {
        qb.And().Term(category)
    }
    
    // Exclude out of stock items
    if excludeOutOfStock {
        qb.And().Not().Term("outofstock")
    }
    
    return qb.ExecuteWithBM25(20)
}</code></pre>

        <h3>Multi-Category Search</h3>
        <pre><code class="language-go">func SearchInCategories(idx *blaze.InvertedIndex, 
                        query string, categories []string) []blaze.Match {
    qb := blaze.NewQueryBuilder(idx).Term(query)
    
    if len(categories) > 0 {
        qb.And().Group(func(q *blaze.QueryBuilder) {
            q.Term(categories[0])
            for i := 1; i < len(categories); i++ {
                q.Or().Term(categories[i])
            }
        })
    }
    
    return qb.ExecuteWithBM25(50)
}</code></pre>

        <h3>Advanced Boolean Search</h3>
        <pre><code class="language-go">// Find documents about (machine learning OR deep learning) 
// AND (python OR tensorflow)
results := blaze.NewQueryBuilder(idx).
    Group(func(q *blaze.QueryBuilder) {
        q.Phrase("machine learning").Or().Phrase("deep learning")
    }).
    And().
    Group(func(q *blaze.QueryBuilder) {
        q.Term("python").Or().Term("tensorflow")
    }).
    ExecuteWithBM25(20)</code></pre>
      </section>

      <section>
        <h2>Use Cases</h2>
        <ul>
          <li>
            <strong>Document Search Systems:</strong> Build full-text search for
            documentation, articles, or knowledge bases
          </li>
          <li>
            <strong>Log Analysis:</strong> Search through application logs with
            boolean queries and ranking
          </li>
          <li>
            <strong>Code Search:</strong> Index and search source code
            repositories
          </li>
          <li>
            <strong>E-commerce:</strong> Product catalog search with filters and
            facets
          </li>
          <li>
            <strong>Email Search:</strong> Fast, local email search without
            external services
          </li>
          <li>
            <strong>Content Management:</strong> Search articles, posts, and
            media metadata
          </li>
        </ul>
      </section>

      <section>
        <h2>Key Features</h2>

        <h3>Search Capabilities</h3>
        <ul>
          <li>Term Search: Find documents containing specific terms</li>
          <li>Phrase Search: Exact multi-word matching</li>
          <li>Boolean Queries: Type-safe AND, OR, NOT operations</li>
          <li>BM25 Ranking: Industry-standard relevance scoring</li>
          <li>Proximity Ranking: Score by term proximity</li>
          <li>Position Tracking: Track exact word positions</li>
        </ul>

        <h3>Text Processing</h3>
        <ul>
          <li>Tokenization: Unicode-aware text splitting</li>
          <li>Stemming: Snowball (Porter2) stemmer</li>
          <li>Stopword Filtering: Remove common words</li>
          <li>Case Normalization: Case-insensitive search</li>
          <li>Configurable Pipeline: Customize analysis behavior</li>
        </ul>

        <h3>Data Structures</h3>
        <ul>
          <li>Roaring Bitmaps: 400x compression for document sets</li>
          <li>Skip Lists: O(log n) position lookups</li>
          <li>Inverted Index: Efficient term-to-position mapping</li>
          <li>Binary Serialization: Compact storage format</li>
        </ul>
      </section>

      <footer>
        <p>
          Built with Go. Licensed under MIT.
          <a href="https://github.com/wizenheimer/blaze">GitHub</a> |
          <a href="https://pkg.go.dev/github.com/wizenheimer/blaze"
            >Documentation</a
          >
        </p>
      </footer>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-go.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
  </body>
</html>
